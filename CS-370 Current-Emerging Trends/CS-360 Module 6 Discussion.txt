The main difference between AlphaGo Zero and its predecessors is that it doesn't use human interactions to help learn. Previous versions of AlphaGo initially trained on thousands of human amateur and professional games to learn how to play Go. AlphaGo Zero skips this step and learns to play simply by playing games against itself, starting from completely random play (Silver & Hassabis, 2017). The other difference that I found interesting was that it doesn't use "rollouts" which are fast games that predict the winner from the current board. It isn't the fact that it doesn't use this that suprises me, it's the fact that the others do that suprises me. If you are training AI why would you skip out on the training to save time or power. Seems very counterintuitive to me. So by leaving out human flaws in strategy and then actually training it, there is almost no way it wouldn't be an improvement.
The thinking of the programs of AlphaGo and AlphaGo Zero is actually fairly similar to human learning and thinking. In AlphaGo Zero especially, it went through stages of learning and just like humans, started off as a beginner and got better through time. It even discovered the same patterns that humans have played. Over the course of millions of AlphaGo vs AlphaGo games, the system progressively learned the game of Go from scratch, accumulating thousands of years of human knowledge during a period of just a few days. AlphaGo Zero also discovered new knowledge, developing unconventional strategies and creative new moves that echoed and surpassed the novel techniques it played in the games against Lee Sedol and Ke Jie (Silver & Hassabis, 2017). In 2016 during a match between AlphaGo and Lee Sedol, AlphaGo made an unexpected play at move 37. Not only the Korean champion, but every single character of the plot (journalists, players, even DeepMindâ€™s team) was shocked. Eventually, the pathos of the scene resulted in a shared feeling: the move was beautiful (Bory, 2019). I guess if humans could live thousands of years and play millions of games also it would be a more even playing field.

Bory, P. (2019). Deep new: The shifting narratives of artificial intelligence from Deep Blue to AlphaGo. Convergence: The International Journal of Research into New Media Technologies, 25(4), 627-642. https://doi.org/10.1177/1354856519829679
Silver, D., & Hassabis, D. (2017, October 18). AlphaGo Zero: Starting from scratch. Retrieved from https://deepmind.google/discover/blog/alphago-zero-starting-from-scratch/